{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Injuries Information + Previous Season Statistics of the Team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T17:00:09.099496Z",
     "iopub.status.busy": "2025-04-08T17:00:09.098971Z",
     "iopub.status.idle": "2025-04-08T17:00:19.976791Z",
     "shell.execute_reply": "2025-04-08T17:00:19.975513Z",
     "shell.execute_reply.started": "2025-04-08T17:00:09.099459Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning 1998500 players from ID 1500 to 1999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing player batches:   0%|          | 5/19985 [00:07<8:31:41,  1.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at index 500, found 128 injuries so far\n",
      "Reached 100 injury records. Stopping early.\n",
      "\n",
      "Found 128 total injuries. Skipped 477 players with no injuries.\n",
      "Processing fixture and opponent information...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing fixtures:   9%|▊         | 11/128 [00:00<00:03, 33.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at 10 processed rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing fixtures:  19%|█▉        | 24/128 [00:00<00:02, 44.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at 20 processed rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing fixtures:  30%|██▉       | 38/128 [00:00<00:01, 48.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at 30 processed rows\n",
      "Checkpoint saved at 40 processed rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing fixtures:  44%|████▍     | 56/128 [00:01<00:01, 45.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at 50 processed rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing fixtures:  52%|█████▏    | 67/128 [00:01<00:01, 42.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at 60 processed rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing fixtures:  60%|██████    | 77/128 [00:01<00:01, 41.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at 70 processed rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing fixtures:  70%|██████▉   | 89/128 [00:02<00:00, 45.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at 80 processed rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing fixtures:  73%|███████▎  | 94/128 [00:02<00:00, 45.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at 90 processed rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing fixtures:  82%|████████▏ | 105/128 [00:02<00:00, 42.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at 100 processed rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing fixtures:  93%|█████████▎| 119/128 [00:02<00:00, 47.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at 110 processed rows\n",
      "Checkpoint saved at 120 processed rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing fixtures: 100%|██████████| 128/128 [00:02<00:00, 44.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final DataFrame with expansions:\n",
      "     injury_player_id fixture_id                injury_date  injury_team_id  \\\n",
      "0                1561    1208527  2024-09-01T19:30:00+00:00             543   \n",
      "1                1561    1208531  2024-09-13T19:00:00+00:00             543   \n",
      "2                1561    1208513  2024-09-18T17:00:00+00:00             543   \n",
      "3                1561    1208540  2024-09-23T19:00:00+00:00             543   \n",
      "4                1561    1208554  2024-09-26T17:00:00+00:00             543   \n",
      "..                ...        ...                        ...             ...   \n",
      "123              1969    1164194  2024-07-21T12:00:00+00:00             378   \n",
      "124              1978    1238053  2025-02-10T17:00:00+00:00            3588   \n",
      "125              1978    1238090  2025-03-09T13:00:00+00:00            3588   \n",
      "126              1978    1238094  2025-03-16T13:00:00+00:00            3588   \n",
      "127              1978    1238108  2025-03-31T17:00:00+00:00            3588   \n",
      "\n",
      "     injury_league_id  injury_season         reason  injuried  \\\n",
      "0                 140           2024  Muscle Injury         1   \n",
      "1                 140           2024  Muscle Injury         1   \n",
      "2                 140           2024  Muscle Injury         1   \n",
      "3                 140           2024  Muscle Injury         1   \n",
      "4                 140           2024  Muscle Injury         1   \n",
      "..                ...            ...            ...       ...   \n",
      "123               113           2024         Injury         1   \n",
      "124               203           2024   Yellow Cards         1   \n",
      "125               203           2024       Red Card         1   \n",
      "126               203           2024       Red Card         1   \n",
      "127               203           2024       Red Card         1   \n",
      "\n",
      "     opponent_team_id prev_inj_team_fixture_1  ... prev_fouls_drawn  \\\n",
      "0                 NaN                     NaN  ...              NaN   \n",
      "1                 NaN                     NaN  ...              NaN   \n",
      "2                 NaN                     NaN  ...              NaN   \n",
      "3                 NaN                     NaN  ...              NaN   \n",
      "4                 NaN               1208540.0  ...              NaN   \n",
      "..                ...                     ...  ...              ...   \n",
      "123               NaN                     NaN  ...              NaN   \n",
      "124               NaN                     NaN  ...              NaN   \n",
      "125             607.0                     NaN  ...              NaN   \n",
      "126               NaN                     NaN  ...              NaN   \n",
      "127             564.0                     NaN  ...              NaN   \n",
      "\n",
      "    prev_fouls_committed prev_cards_yellow prev_cards_yellowred  \\\n",
      "0                    NaN               NaN                  NaN   \n",
      "1                    NaN               NaN                  NaN   \n",
      "2                    NaN               NaN                  NaN   \n",
      "3                    NaN               NaN                  NaN   \n",
      "4                    NaN               NaN                  NaN   \n",
      "..                   ...               ...                  ...   \n",
      "123                  NaN               NaN                  NaN   \n",
      "124                  NaN               NaN                  NaN   \n",
      "125                  NaN               NaN                  NaN   \n",
      "126                  NaN               NaN                  NaN   \n",
      "127                  NaN               NaN                  NaN   \n",
      "\n",
      "    prev_cards_red prev_penalty_won prev_penalty_commited prev_penalty_scored  \\\n",
      "0              NaN              NaN                   NaN                 NaN   \n",
      "1              NaN              NaN                   NaN                 NaN   \n",
      "2              NaN              NaN                   NaN                 NaN   \n",
      "3              NaN              NaN                   NaN                 NaN   \n",
      "4              NaN              NaN                   NaN                 NaN   \n",
      "..             ...              ...                   ...                 ...   \n",
      "123            NaN              NaN                   NaN                 NaN   \n",
      "124            NaN              NaN                   NaN                 NaN   \n",
      "125            NaN              NaN                   NaN                 NaN   \n",
      "126            NaN              NaN                   NaN                 NaN   \n",
      "127            NaN              NaN                   NaN                 NaN   \n",
      "\n",
      "    prev_penalty_missed  prev_penalty_saved  \n",
      "0                   NaN                 NaN  \n",
      "1                   NaN                 NaN  \n",
      "2                   NaN                 NaN  \n",
      "3                   NaN                 NaN  \n",
      "4                   NaN                 NaN  \n",
      "..                  ...                 ...  \n",
      "123                 NaN                 NaN  \n",
      "124                 NaN                 NaN  \n",
      "125                 NaN                 NaN  \n",
      "126                 NaN                 NaN  \n",
      "127                 NaN                 NaN  \n",
      "\n",
      "[128 rows x 78 columns]\n",
      "\n",
      "Saved 477 negative-sample players to negative_samples.csv\n",
      "API cache size: 1402 entries\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n",
      "  has_large_values = (abs_vals > 1e6).any()\n",
      "/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n",
      "/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n"
     ]
    }
   ],
   "source": [
    "import http.client\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import concurrent.futures\n",
    "from functools import lru_cache\n",
    "import os\n",
    "\n",
    "#####################\n",
    "# Configurable Variables\n",
    "#####################\n",
    "API_KEY = \"xxx\"\n",
    "SEASON = 2024\n",
    "PREV_SEASON = SEASON - 1\n",
    "\n",
    "SEASON_START = f\"{SEASON}-08-01\"   # e.g. \"2024-08-01\"\n",
    "NUM_PREV_FIXTURES = 5              # Number of previous fixtures to retrieve\n",
    "PLAYER_IDS = list(range(1500, 2000000))  # Large range for demonstration\n",
    "\n",
    "SAVE_EVERY_N_ROWS = 10             # Save progress every N merges\n",
    "TARGET_INJURY_RECORDS = 100       # STOP once we have found this many injuries\n",
    "CHECKPOINT_FILE = \"player_scan_checkpoint.json\"  # To resume scanning from last position\n",
    "\n",
    "# Rate limiting and parallel processing\n",
    "MAX_WORKERS = 10                   # Number of concurrent API calls\n",
    "MAX_RETRIES = 9999999                    # Retries for failed API calls\n",
    "REQUEST_TIMEOUT = 10               # Seconds for request timeout\n",
    "CACHE_DIR = \"api_cache\"            # Directory to store cached API responses\n",
    "\n",
    "# Create cache directory if it doesn't exist\n",
    "os.makedirs(CACHE_DIR, exist_ok=True)\n",
    "\n",
    "#####################\n",
    "# Connection and Caching Setup\n",
    "#####################\n",
    "\n",
    "# LRU cache for API responses\n",
    "cache = {}\n",
    "\n",
    "def get_cache_key(endpoint):\n",
    "    \"\"\"Generate a cache key for an endpoint\"\"\"\n",
    "    return endpoint.replace(\"/\", \"_\").replace(\"?\", \"_\").replace(\"&\", \"_\").replace(\"=\", \"_\")\n",
    "\n",
    "def cache_api_response(endpoint, response):\n",
    "    \"\"\"Cache an API response both in memory and on disk\"\"\"\n",
    "    key = get_cache_key(endpoint)\n",
    "    cache[endpoint] = response\n",
    "    \n",
    "    cache_file = os.path.join(CACHE_DIR, f\"{key}.json\")\n",
    "    try:\n",
    "        with open(cache_file, 'w') as f:\n",
    "            json.dump(response, f)\n",
    "    except Exception as e:\n",
    "        print(f\"Error caching to disk: {e}\")\n",
    "\n",
    "def get_cached_response(endpoint):\n",
    "    \"\"\"Try to get a response from cache (memory first, then disk)\"\"\"\n",
    "    # Check memory cache\n",
    "    if endpoint in cache:\n",
    "        return cache[endpoint]\n",
    "    \n",
    "    # Check disk cache\n",
    "    key = get_cache_key(endpoint)\n",
    "    cache_file = os.path.join(CACHE_DIR, f\"{key}.json\")\n",
    "    try:\n",
    "        if os.path.exists(cache_file):\n",
    "            with open(cache_file, 'r') as f:\n",
    "                response = json.load(f)\n",
    "                # Store in memory cache for faster access next time\n",
    "                cache[endpoint] = response\n",
    "                return response\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading cache: {e}\")\n",
    "    \n",
    "    return None\n",
    "\n",
    "def create_connection():\n",
    "    \"\"\"Create a new connection to the API\"\"\"\n",
    "    return http.client.HTTPSConnection(\"v3.football.api-sports.io\", timeout=REQUEST_TIMEOUT)\n",
    "\n",
    "def make_api_request(endpoint, headers=None):\n",
    "    \"\"\"Make an API request with retries and caching\"\"\"\n",
    "    if headers is None:\n",
    "        headers = {\n",
    "            \"x-rapidapi-host\": \"v3.football.api-sports.io\",\n",
    "            \"x-rapidapi-key\": API_KEY\n",
    "        }\n",
    "    \n",
    "    # Check cache first\n",
    "    cached_response = get_cached_response(endpoint)\n",
    "    if cached_response:\n",
    "        return cached_response\n",
    "    \n",
    "    # Make the request with retries\n",
    "    for attempt in range(MAX_RETRIES):\n",
    "        try:\n",
    "            conn = create_connection()\n",
    "            conn.request(\"GET\", endpoint, headers=headers)\n",
    "            res = conn.getresponse()\n",
    "            data = res.read()\n",
    "            \n",
    "            # Check for rate limiting\n",
    "            if res.status == 429:\n",
    "                wait_time = (attempt + 1) * 2  # Exponential backoff\n",
    "                print(f\"Rate limited. Waiting {wait_time}s before retry {attempt+1}\")\n",
    "                time.sleep(wait_time)\n",
    "                continue\n",
    "                \n",
    "            response = json.loads(data.decode(\"utf-8\"))\n",
    "            \n",
    "            # Cache the successful response\n",
    "            cache_api_response(endpoint, response)\n",
    "            \n",
    "            return response\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error on attempt {attempt+1} for {endpoint}: {e}\")\n",
    "            if attempt < MAX_RETRIES - 1:\n",
    "                wait_time = (attempt + 1) * 2\n",
    "                time.sleep(wait_time)\n",
    "            else:\n",
    "                print(f\"Max retries reached for {endpoint}. Giving up.\")\n",
    "                return None\n",
    "        finally:\n",
    "            if 'conn' in locals():\n",
    "                conn.close()\n",
    "    \n",
    "    return None\n",
    "\n",
    "#####################\n",
    "# Helper: Flatten Player Stats\n",
    "#####################\n",
    "def flatten_player_stats(player_response):\n",
    "    \"\"\"\n",
    "    Flattens a single /players response item, generating a list of dictionaries \n",
    "    (one per league/team statistic). \n",
    "    \"\"\"\n",
    "    flattened_list = []\n",
    "    player_info = player_response.get(\"player\", {})\n",
    "    player_dict = {\n",
    "        \"player_id\": player_info.get(\"id\"),\n",
    "        \"player_name\": player_info.get(\"name\"),\n",
    "        \"player_firstname\": player_info.get(\"firstname\"),\n",
    "        \"player_lastname\": player_info.get(\"lastname\"),\n",
    "        \"player_age\": player_info.get(\"age\"),\n",
    "        \"player_birth_date\": player_info.get(\"birth\", {}).get(\"date\"),\n",
    "        \"player_birth_place\": player_info.get(\"birth\", {}).get(\"place\"),\n",
    "        \"player_birth_country\": player_info.get(\"birth\", {}).get(\"country\"),\n",
    "        \"player_nationality\": player_info.get(\"nationality\"),\n",
    "        \"player_height\": player_info.get(\"height\"),\n",
    "        \"player_weight\": player_info.get(\"weight\"),\n",
    "        \"player_injured\": player_info.get(\"injured\"),\n",
    "        \"player_photo\": player_info.get(\"photo\")\n",
    "    }\n",
    "\n",
    "    statistics = player_response.get(\"statistics\", [])\n",
    "    if not statistics:\n",
    "        # If no stats, just add the base dict\n",
    "        flattened_list.append(player_dict)\n",
    "    else:\n",
    "        # For each league/team stat block, create a record\n",
    "        for stat in statistics:\n",
    "            record = player_dict.copy()\n",
    "            team = stat.get(\"team\", {})\n",
    "            record[\"team_id\"] = team.get(\"id\")\n",
    "            record[\"team_name\"] = team.get(\"name\")\n",
    "            record[\"team_logo\"] = team.get(\"logo\")\n",
    "\n",
    "            league = stat.get(\"league\", {})\n",
    "            record[\"league_id\"] = league.get(\"id\")\n",
    "            record[\"league_name\"] = league.get(\"name\")\n",
    "            record[\"league_country\"] = league.get(\"country\")\n",
    "            record[\"league_logo\"] = league.get(\"logo\")\n",
    "            record[\"league_flag\"] = league.get(\"flag\")\n",
    "            record[\"league_season\"] = league.get(\"season\")\n",
    "\n",
    "            games = stat.get(\"games\", {})\n",
    "            record[\"games_appearences\"] = games.get(\"appearences\")\n",
    "            record[\"games_lineups\"] = games.get(\"lineups\")\n",
    "            record[\"games_minutes\"] = games.get(\"minutes\")\n",
    "            record[\"games_number\"] = games.get(\"number\")\n",
    "            record[\"games_position\"] = games.get(\"position\")\n",
    "            record[\"games_rating\"] = games.get(\"rating\")\n",
    "            record[\"games_captain\"] = games.get(\"captain\")\n",
    "\n",
    "            substitutes = stat.get(\"substitutes\", {})\n",
    "            record[\"substitutes_in\"] = substitutes.get(\"in\")\n",
    "            record[\"substitutes_out\"] = substitutes.get(\"out\")\n",
    "            record[\"substitutes_bench\"] = substitutes.get(\"bench\")\n",
    "\n",
    "            shots = stat.get(\"shots\", {})\n",
    "            record[\"shots_total\"] = shots.get(\"total\")\n",
    "            record[\"shots_on\"] = shots.get(\"on\")\n",
    "\n",
    "            goals = stat.get(\"goals\", {})\n",
    "            record[\"goals_total\"] = goals.get(\"total\")\n",
    "            record[\"goals_conceded\"] = goals.get(\"conceded\")\n",
    "            record[\"goals_assists\"] = goals.get(\"assists\")\n",
    "            record[\"goals_saves\"] = goals.get(\"saves\")\n",
    "\n",
    "            passes = stat.get(\"passes\", {})\n",
    "            record[\"passes_total\"] = passes.get(\"total\")\n",
    "            record[\"passes_key\"] = passes.get(\"key\")\n",
    "            record[\"passes_accuracy\"] = passes.get(\"accuracy\")\n",
    "\n",
    "            tackles = stat.get(\"tackles\", {})\n",
    "            record[\"tackles_total\"] = tackles.get(\"total\")\n",
    "            record[\"tackles_blocks\"] = tackles.get(\"blocks\")\n",
    "            record[\"tackles_interceptions\"] = tackles.get(\"interceptions\")\n",
    "\n",
    "            duels = stat.get(\"duels\", {})\n",
    "            record[\"duels_total\"] = duels.get(\"total\")\n",
    "            record[\"duels_won\"] = duels.get(\"won\")\n",
    "\n",
    "            dribbles = stat.get(\"dribbles\", {})\n",
    "            record[\"dribbles_attempts\"] = dribbles.get(\"attempts\")\n",
    "            record[\"dribbles_success\"] = dribbles.get(\"success\")\n",
    "            record[\"dribbles_past\"] = dribbles.get(\"past\")\n",
    "\n",
    "            fouls = stat.get(\"fouls\", {})\n",
    "            record[\"fouls_drawn\"] = fouls.get(\"drawn\")\n",
    "            record[\"fouls_committed\"] = fouls.get(\"committed\")\n",
    "\n",
    "            cards = stat.get(\"cards\", {})\n",
    "            record[\"cards_yellow\"] = cards.get(\"yellow\")\n",
    "            record[\"cards_yellowred\"] = cards.get(\"yellowred\")\n",
    "            record[\"cards_red\"] = cards.get(\"red\")\n",
    "\n",
    "            penalty = stat.get(\"penalty\", {})\n",
    "            record[\"penalty_won\"] = penalty.get(\"won\")\n",
    "            record[\"penalty_commited\"] = penalty.get(\"commited\")\n",
    "            record[\"penalty_scored\"] = penalty.get(\"scored\")\n",
    "            record[\"penalty_missed\"] = penalty.get(\"missed\")\n",
    "            record[\"penalty_saved\"] = penalty.get(\"saved\")\n",
    "\n",
    "            flattened_list.append(record)\n",
    "    return flattened_list\n",
    "\n",
    "#####################\n",
    "# Process Players in Batches\n",
    "#####################\n",
    "def process_player_batch(player_ids):\n",
    "    \"\"\"Process a batch of players in parallel, returning injuries and previous season stats\"\"\"\n",
    "    local_injuries_list = []\n",
    "    local_flattened_stats_prev = {}\n",
    "    local_no_injury_ids = []\n",
    "    \n",
    "    def process_single_player(player_id):\n",
    "        \"\"\"Process a single player, returning injuries and previous season stats\"\"\"\n",
    "        # Get previous season stats\n",
    "        endpoint_stats_prev = f\"/players?id={player_id}&season={PREV_SEASON}\"\n",
    "        json_stats_prev = make_api_request(endpoint_stats_prev)\n",
    "        \n",
    "        prev_stats = {}\n",
    "        if json_stats_prev and json_stats_prev.get(\"response\"):\n",
    "            try:\n",
    "                player_response_prev = json_stats_prev[\"response\"][0]\n",
    "                flat_list_prev = flatten_player_stats(player_response_prev)\n",
    "                if flat_list_prev:\n",
    "                    prefixed_record = {\"prev_\" + k: v for k, v in flat_list_prev[0].items()}\n",
    "                    prev_stats = prefixed_record\n",
    "            except Exception as e:\n",
    "                print(f\"Problem flattening stats for player {player_id}: {e}\")\n",
    "        \n",
    "        # Get current season injuries\n",
    "        endpoint_injuries = f\"/injuries?player={player_id}&season={SEASON}\"\n",
    "        json_injuries = make_api_request(endpoint_injuries)\n",
    "        \n",
    "        player_injuries = json_injuries.get(\"response\", []) if json_injuries else []\n",
    "        \n",
    "        injuries = []\n",
    "        if not player_injuries:\n",
    "            return {\"player_id\": player_id, \"injuries\": [], \"prev_stats\": prev_stats, \"has_injury\": False}\n",
    "        \n",
    "        # Process injuries\n",
    "        for injury in player_injuries:\n",
    "            try:\n",
    "                fixture_id = int(injury[\"fixture\"][\"id\"])\n",
    "            except:\n",
    "                fixture_id = None\n",
    "                \n",
    "            injuries.append({\n",
    "                \"injury_player_id\": injury[\"player\"][\"id\"],\n",
    "                \"fixture_id\": fixture_id,\n",
    "                \"injury_date\": injury[\"fixture\"][\"date\"],\n",
    "                \"injury_team_id\": injury[\"team\"][\"id\"],\n",
    "                \"injury_league_id\": injury[\"league\"][\"id\"],\n",
    "                \"injury_season\": injury[\"league\"][\"season\"],\n",
    "                \"reason\": injury[\"player\"][\"reason\"],\n",
    "                \"injuried\": 1\n",
    "            })\n",
    "        \n",
    "        return {\"player_id\": player_id, \"injuries\": injuries, \"prev_stats\": prev_stats, \"has_injury\": True}\n",
    "    \n",
    "    # Process players in parallel\n",
    "    results = []\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "        futures = {executor.submit(process_single_player, pid): pid for pid in player_ids}\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            pid = futures[future]\n",
    "            try:\n",
    "                result = future.result()\n",
    "                results.append(result)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing player {pid}: {e}\")\n",
    "    \n",
    "    # Compile results\n",
    "    for result in results:\n",
    "        if result[\"has_injury\"]:\n",
    "            local_injuries_list.extend(result[\"injuries\"])\n",
    "            if result[\"prev_stats\"]:\n",
    "                local_flattened_stats_prev[result[\"player_id\"]] = result[\"prev_stats\"]\n",
    "        else:\n",
    "            local_no_injury_ids.append(result[\"player_id\"])\n",
    "    \n",
    "    return local_injuries_list, local_flattened_stats_prev, local_no_injury_ids\n",
    "\n",
    "#####################\n",
    "# Helper functions for fixture and opponent info\n",
    "#####################\n",
    "def get_opponent_team_id(fixture_id, injury_team_id):\n",
    "    \"\"\"Get opponent team ID for a fixture\"\"\"\n",
    "    if not fixture_id:\n",
    "        return None\n",
    "        \n",
    "    endpoint = f\"/fixtures?fixture={fixture_id}\"\n",
    "    json_fixture = make_api_request(endpoint)\n",
    "    \n",
    "    fixtures = json_fixture.get(\"response\", []) if json_fixture else []\n",
    "    opponent = None\n",
    "    \n",
    "    if fixtures:\n",
    "        teams = fixtures[0].get(\"teams\", {})\n",
    "        home = teams.get(\"home\", {}).get(\"id\")\n",
    "        away = teams.get(\"away\", {}).get(\"id\")\n",
    "        try:\n",
    "            home = int(home) if home is not None else None\n",
    "            away = int(away) if away is not None else None\n",
    "        except:\n",
    "            home, away = None, None\n",
    "        if injury_team_id == home:\n",
    "            opponent = away\n",
    "        elif injury_team_id == away:\n",
    "            opponent = home\n",
    "\n",
    "    if opponent is None:\n",
    "        # fallback\n",
    "        endpoint_stats = f\"/fixtures/statistics?fixture={fixture_id}\"\n",
    "        json_stats = make_api_request(endpoint_stats)\n",
    "        responses = json_stats.get(\"response\", []) if json_stats else []\n",
    "        \n",
    "        if len(responses) == 2:\n",
    "            try:\n",
    "                team1 = int(responses[0].get(\"team\", {}).get(\"id\"))\n",
    "                team2 = int(responses[1].get(\"team\", {}).get(\"id\"))\n",
    "            except:\n",
    "                team1, team2 = None, None\n",
    "            if injury_team_id == team1:\n",
    "                opponent = team2\n",
    "            elif injury_team_id == team2:\n",
    "                opponent = team1\n",
    "\n",
    "    return opponent\n",
    "\n",
    "def get_previous_fixture_ids(team_id, season, current_fixture_date, current_fixture_id, k=NUM_PREV_FIXTURES, season_start=SEASON_START):\n",
    "    \"\"\"Get previous fixture IDs for a team before a specific date\"\"\"\n",
    "    if not team_id or not current_fixture_date:\n",
    "        return [None] * k\n",
    "        \n",
    "    date_only = current_fixture_date.split(\"T\")[0]\n",
    "    endpoint = f\"/fixtures?team={team_id}&season={season}&from={season_start}&to={date_only}\"\n",
    "    json_fixtures = make_api_request(endpoint)\n",
    "    \n",
    "    fixtures = json_fixtures.get(\"response\", []) if json_fixtures else []\n",
    "    \n",
    "    prev_fixtures = []\n",
    "    for fix in fixtures:\n",
    "        try:\n",
    "            fid = int(fix[\"fixture\"][\"id\"])\n",
    "        except:\n",
    "            fid = None\n",
    "        if fid is not None and fid != current_fixture_id:\n",
    "            prev_fixtures.append((fix[\"fixture\"][\"date\"], fid))\n",
    "    \n",
    "    if not prev_fixtures:\n",
    "        return [None] * k\n",
    "\n",
    "    prev_fixtures.sort(key=lambda x: x[0], reverse=True)\n",
    "    prev_ids = [fid for _, fid in prev_fixtures[:k]]\n",
    "    while len(prev_ids) < k:\n",
    "        prev_ids.append(None)\n",
    "    return prev_ids\n",
    "\n",
    "def process_fixture_info(row_data):\n",
    "    \"\"\"Process fixture and opponent info for a single injury row\"\"\"\n",
    "    fixture_id = row_data[\"fixture_id\"]\n",
    "    injury_team_id = row_data[\"injury_team_id\"]\n",
    "    injury_date = row_data[\"injury_date\"]\n",
    "    injury_season = row_data[\"injury_season\"]\n",
    "    \n",
    "    # Get opponent team ID\n",
    "    opp_team_id = get_opponent_team_id(fixture_id, injury_team_id)\n",
    "    \n",
    "    # Get previous fixtures for injury team\n",
    "    inj_team_fix = get_previous_fixture_ids(injury_team_id, injury_season, injury_date, fixture_id)\n",
    "    \n",
    "    # Get previous fixtures for opponent team\n",
    "    if opp_team_id:\n",
    "        opp_team_fix = get_previous_fixture_ids(opp_team_id, injury_season, injury_date, fixture_id)\n",
    "    else:\n",
    "        opp_team_fix = [None] * NUM_PREV_FIXTURES\n",
    "    \n",
    "    result = {\n",
    "        \"opponent_team_id\": opp_team_id\n",
    "    }\n",
    "    \n",
    "    # Add previous fixtures\n",
    "    for j in range(NUM_PREV_FIXTURES):\n",
    "        result[f\"prev_inj_team_fixture_{j+1}\"] = inj_team_fix[j]\n",
    "        result[f\"prev_opp_team_fixture_{j+1}\"] = opp_team_fix[j]\n",
    "    \n",
    "    return result\n",
    "\n",
    "#####################\n",
    "# Main execution function\n",
    "#####################\n",
    "def main():\n",
    "    injuries_list = []\n",
    "    flattened_stats_prev = {}\n",
    "    no_injury_ids = []\n",
    "    \n",
    "    # Check for checkpoint to resume scanning\n",
    "    start_idx = 0\n",
    "    if os.path.exists(CHECKPOINT_FILE):\n",
    "        try:\n",
    "            with open(CHECKPOINT_FILE, 'r') as f:\n",
    "                checkpoint = json.load(f)\n",
    "                start_idx = checkpoint.get(\"last_processed_idx\", 0)\n",
    "                print(f\"Resuming from checkpoint at index {start_idx}\")\n",
    "                \n",
    "                # Load cached data if available\n",
    "                if \"injuries_count\" in checkpoint:\n",
    "                    injuries_list = checkpoint.get(\"injuries_list\", [])\n",
    "                    flattened_stats_prev = checkpoint.get(\"flattened_stats_prev\", {})\n",
    "                    no_injury_ids = checkpoint.get(\"no_injury_ids\", [])\n",
    "                    print(f\"Loaded {len(injuries_list)} injuries from checkpoint\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading checkpoint: {e}\")\n",
    "    \n",
    "    # Prepare to scan players\n",
    "    remaining_player_ids = PLAYER_IDS[start_idx:]\n",
    "    print(f\"Scanning {len(remaining_player_ids)} players from ID {remaining_player_ids[0]} to {remaining_player_ids[-1]}\")\n",
    "    \n",
    "    # Process players in batches for better progress tracking\n",
    "    BATCH_SIZE = 100\n",
    "    injury_count = len(injuries_list)\n",
    "    \n",
    "    for batch_start in tqdm(range(0, len(remaining_player_ids), BATCH_SIZE), desc=\"Processing player batches\"):\n",
    "        if injury_count >= TARGET_INJURY_RECORDS:\n",
    "            print(f\"Reached {TARGET_INJURY_RECORDS} injury records. Stopping early.\")\n",
    "            break\n",
    "            \n",
    "        batch_end = min(batch_start + BATCH_SIZE, len(remaining_player_ids))\n",
    "        batch_ids = remaining_player_ids[batch_start:batch_end]\n",
    "        \n",
    "        # Process batch\n",
    "        batch_injuries, batch_stats, batch_no_injury = process_player_batch(batch_ids)\n",
    "        \n",
    "        # Update totals\n",
    "        injuries_list.extend(batch_injuries)\n",
    "        injury_count += len(batch_injuries)\n",
    "        flattened_stats_prev.update(batch_stats)\n",
    "        no_injury_ids.extend(batch_no_injury)\n",
    "        \n",
    "        # Save checkpoint periodically\n",
    "        global_idx = start_idx + batch_end\n",
    "        if batch_end % (BATCH_SIZE * 5) == 0 or injury_count >= TARGET_INJURY_RECORDS:\n",
    "            checkpoint = {\n",
    "                \"last_processed_idx\": global_idx,\n",
    "                \"injuries_count\": len(injuries_list),\n",
    "                \"injuries_list\": injuries_list,\n",
    "                \"flattened_stats_prev\": flattened_stats_prev,\n",
    "                \"no_injury_ids\": no_injury_ids\n",
    "            }\n",
    "            with open(CHECKPOINT_FILE, 'w') as f:\n",
    "                json.dump(checkpoint, f)\n",
    "            print(f\"Checkpoint saved at index {global_idx}, found {len(injuries_list)} injuries so far\")\n",
    "    \n",
    "    print(f\"\\nFound {len(injuries_list)} total injuries. Skipped {len(no_injury_ids)} players with no injuries.\")\n",
    "    \n",
    "    # Create DataFrame from injuries\n",
    "    if injuries_list:\n",
    "        df = pd.DataFrame(injuries_list)\n",
    "        df.to_csv(\"players.csv\", index=False)\n",
    "        \n",
    "        # Process fixture info in parallel\n",
    "        print(\"Processing fixture and opponent information...\")\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "            future_to_idx = {\n",
    "                executor.submit(process_fixture_info, row): i \n",
    "                for i, row in df.iterrows()\n",
    "            }\n",
    "            \n",
    "            results = []\n",
    "            for future in tqdm(concurrent.futures.as_completed(future_to_idx), \n",
    "                               total=len(future_to_idx), \n",
    "                               desc=\"Processing fixtures\"):\n",
    "                idx = future_to_idx[future]\n",
    "                try:\n",
    "                    result = future.result()\n",
    "                    results.append((idx, result))\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing fixture for row {idx}: {e}\")\n",
    "                    results.append((idx, {}))\n",
    "                \n",
    "                # Save checkpoint periodically\n",
    "                if len(results) % SAVE_EVERY_N_ROWS == 0:\n",
    "                    df.to_csv(\"checkpoint_injuries.csv\", index=False)\n",
    "                    print(f\"Checkpoint saved at {len(results)} processed rows\")\n",
    "            \n",
    "            # Sort results by index\n",
    "            results.sort(key=lambda x: x[0])\n",
    "            \n",
    "            # Apply results to DataFrame\n",
    "            opponent_team_ids = []\n",
    "            prev_inj_team_fixtures = {f\"prev_inj_team_fixture_{i+1}\": [] for i in range(NUM_PREV_FIXTURES)}\n",
    "            prev_opp_team_fixtures = {f\"prev_opp_team_fixture_{i+1}\": [] for i in range(NUM_PREV_FIXTURES)}\n",
    "            \n",
    "            for _, result in results:\n",
    "                opponent_team_ids.append(result.get(\"opponent_team_id\"))\n",
    "                for j in range(NUM_PREV_FIXTURES):\n",
    "                    col_inj = f\"prev_inj_team_fixture_{j+1}\"\n",
    "                    col_opp = f\"prev_opp_team_fixture_{j+1}\"\n",
    "                    prev_inj_team_fixtures[col_inj].append(result.get(col_inj))\n",
    "                    prev_opp_team_fixtures[col_opp].append(result.get(col_opp))\n",
    "            \n",
    "            # Add columns to DataFrame\n",
    "            df[\"opponent_team_id\"] = opponent_team_ids\n",
    "            for col, values in prev_inj_team_fixtures.items():\n",
    "                df[col] = values\n",
    "            for col, values in prev_opp_team_fixtures.items():\n",
    "                df[col] = values\n",
    "            \n",
    "            # Add previous season info\n",
    "            prev_info_list = []\n",
    "            for player_id in df[\"injury_player_id\"]:\n",
    "                prev_info = flattened_stats_prev.get(player_id, {})\n",
    "                prev_info_list.append(prev_info)\n",
    "            \n",
    "            prev_info_df = pd.DataFrame(prev_info_list)\n",
    "            df = pd.concat([df, prev_info_df], axis=1)\n",
    "            \n",
    "            # Convert fixture ID columns to avoid float formatting\n",
    "            fixture_cols = [\"fixture_id\"] + \\\n",
    "                        [f\"prev_inj_team_fixture_{i+1}\" for i in range(NUM_PREV_FIXTURES)] + \\\n",
    "                        [f\"prev_opp_team_fixture_{i+1}\" for i in range(NUM_PREV_FIXTURES)]\n",
    "            for col in fixture_cols:\n",
    "                df[col] = df[col].astype(\"object\")\n",
    "            \n",
    "            print(\"\\nFinal DataFrame with expansions:\")\n",
    "            print(df)\n",
    "            df.to_csv(\"final_df.csv\", index=False)\n",
    "    else:\n",
    "        print(\"\\nNo injuries at all. Skipping fixture expansions.\")\n",
    "    \n",
    "    # Save negative samples\n",
    "    if no_injury_ids:\n",
    "        pd.DataFrame({\"player_id\": no_injury_ids}).to_csv(\"negative_samples.csv\", index=False)\n",
    "        print(f\"\\nSaved {len(no_injury_ids)} negative-sample players to negative_samples.csv\")\n",
    "    else:\n",
    "        print(\"\\nNo negative samples were found (all players had injuries).\")\n",
    "    \n",
    "    # Clean up\n",
    "    print(f\"API cache size: {len(cache)} entries\")\n",
    "    print(\"Done!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T17:08:03.903372Z",
     "iopub.status.busy": "2025-04-08T17:08:03.902910Z",
     "iopub.status.idle": "2025-04-08T17:08:03.940031Z",
     "shell.execute_reply": "2025-04-08T17:08:03.938802Z",
     "shell.execute_reply.started": "2025-04-08T17:08:03.903336Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"final_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T17:08:05.431697Z",
     "iopub.status.busy": "2025-04-08T17:08:05.431302Z",
     "iopub.status.idle": "2025-04-08T17:08:05.442651Z",
     "shell.execute_reply": "2025-04-08T17:08:05.441544Z",
     "shell.execute_reply.started": "2025-04-08T17:08:05.431665Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df[['injury_player_id', 'fixture_id','injury_team_id',\n",
    "       'injury_league_id', 'injury_season','opponent_team_id', 'prev_inj_team_fixture_1',\n",
    "       'prev_inj_team_fixture_2', 'prev_inj_team_fixture_3',\n",
    "       'prev_inj_team_fixture_4', 'prev_inj_team_fixture_5',\n",
    "       'prev_opp_team_fixture_1', 'prev_opp_team_fixture_2',\n",
    "       'prev_opp_team_fixture_3', 'prev_opp_team_fixture_4',\n",
    "       'prev_opp_team_fixture_5']] = df[['injury_player_id', 'fixture_id','injury_team_id',\n",
    "       'injury_league_id', 'injury_season','opponent_team_id', 'prev_inj_team_fixture_1',\n",
    "       'prev_inj_team_fixture_2', 'prev_inj_team_fixture_3',\n",
    "       'prev_inj_team_fixture_4', 'prev_inj_team_fixture_5',\n",
    "       'prev_opp_team_fixture_1', 'prev_opp_team_fixture_2',\n",
    "       'prev_opp_team_fixture_3', 'prev_opp_team_fixture_4',\n",
    "       'prev_opp_team_fixture_5']].fillna(-1).astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Previous 5 Matches Player, Team and Opponent Raw Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T17:08:14.857415Z",
     "iopub.status.busy": "2025-04-08T17:08:14.857030Z",
     "iopub.status.idle": "2025-04-08T17:08:58.111626Z",
     "shell.execute_reply": "2025-04-08T17:08:58.110637Z",
     "shell.execute_reply.started": "2025-04-08T17:08:14.857384Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing columns in df: Index(['injury_player_id', 'fixture_id', 'injury_date', 'injury_team_id',\n",
      "       'injury_league_id', 'injury_season', 'reason', 'injuried',\n",
      "       'opponent_team_id', 'prev_inj_team_fixture_1',\n",
      "       'prev_inj_team_fixture_2', 'prev_inj_team_fixture_3',\n",
      "       'prev_inj_team_fixture_4', 'prev_inj_team_fixture_5',\n",
      "       'prev_opp_team_fixture_1', 'prev_opp_team_fixture_2',\n",
      "       'prev_opp_team_fixture_3', 'prev_opp_team_fixture_4',\n",
      "       'prev_opp_team_fixture_5', 'prev_player_id', 'prev_player_name',\n",
      "       'prev_player_firstname', 'prev_player_lastname', 'prev_player_age',\n",
      "       'prev_player_birth_date', 'prev_player_birth_place',\n",
      "       'prev_player_birth_country', 'prev_player_nationality',\n",
      "       'prev_player_height', 'prev_player_weight', 'prev_player_injured',\n",
      "       'prev_player_photo', 'prev_team_id', 'prev_team_name', 'prev_team_logo',\n",
      "       'prev_league_id', 'prev_league_name', 'prev_league_country',\n",
      "       'prev_league_logo', 'prev_league_flag', 'prev_league_season',\n",
      "       'prev_games_appearences', 'prev_games_lineups', 'prev_games_minutes',\n",
      "       'prev_games_number', 'prev_games_position', 'prev_games_rating',\n",
      "       'prev_games_captain', 'prev_substitutes_in', 'prev_substitutes_out',\n",
      "       'prev_substitutes_bench', 'prev_shots_total', 'prev_shots_on',\n",
      "       'prev_goals_total', 'prev_goals_conceded', 'prev_goals_assists',\n",
      "       'prev_goals_saves', 'prev_passes_total', 'prev_passes_key',\n",
      "       'prev_passes_accuracy', 'prev_tackles_total', 'prev_tackles_blocks',\n",
      "       'prev_tackles_interceptions', 'prev_duels_total', 'prev_duels_won',\n",
      "       'prev_dribbles_attempts', 'prev_dribbles_success', 'prev_dribbles_past',\n",
      "       'prev_fouls_drawn', 'prev_fouls_committed', 'prev_cards_yellow',\n",
      "       'prev_cards_yellowred', 'prev_cards_red', 'prev_penalty_won',\n",
      "       'prev_penalty_commited', 'prev_penalty_scored', 'prev_penalty_missed',\n",
      "       'prev_penalty_saved'],\n",
      "      dtype='object')\n",
      "Starting parallel processing of API calls...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows: 100%|██████████| 1000/1000 [00:42<00:00, 23.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stage 1 complete! df now has raw data columns:\n",
      "                       raw_player_team_fixture_stats  \\\n",
      "0  [{'games': {'minutes': None, 'number': 25, 'po...   \n",
      "1  [None, {'games': {'minutes': None, 'number': 2...   \n",
      "2  [None, None, {'games': {'minutes': None, 'numb...   \n",
      "3  [None, None, None, None, {'games': {'minutes':...   \n",
      "4  [None, {'games': {'minutes': 86, 'number': 5, ...   \n",
      "\n",
      "                          raw_team_fixture_agg_stats  \\\n",
      "0  [{'shots_on_goal': 6, 'shots_off_goal': 5, 'to...   \n",
      "1                     [None, None, None, None, None]   \n",
      "2  [{'shots_on_goal': 7, 'shots_off_goal': 3, 'to...   \n",
      "3  [None, None, {'shots_on_goal': 7, 'shots_off_g...   \n",
      "4  [{'shots_on_goal': 7, 'shots_off_goal': 8, 'to...   \n",
      "\n",
      "                           raw_opp_fixture_agg_stats  \n",
      "0                     [None, None, None, None, None]  \n",
      "1                     [None, None, None, None, None]  \n",
      "2  [{'shots_on_goal': 6, 'shots_off_goal': 2, 'to...  \n",
      "3  [None, {'shots_on_goal': 4, 'shots_off_goal': ...  \n",
      "4  [None, {'shots_on_goal': 9, 'shots_off_goal': ...  \n",
      "Cache hits: 6842\n",
      "Cache misses: 8158\n",
      "Cache size: 5475 entries\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import http.client\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import concurrent.futures\n",
    "from functools import lru_cache\n",
    "\n",
    "#####################\n",
    "# 0. CONFIG / SETUP\n",
    "#####################\n",
    "API_KEY = \"xxx\"   # Replace with your API key\n",
    "TIME_BETWEEN_CALLS = 0.05  # Small delay between parallel batches\n",
    "MAX_RETRIES = 9999999            # How many times to retry if a call fails\n",
    "RETRY_WAIT_SECONDS = 2.0   # Wait this long before each retry\n",
    "MAX_WORKERS = 10           # Number of parallel workers (adjust based on API limits)\n",
    "\n",
    "# Create connection pool\n",
    "def create_connection():\n",
    "    conn = http.client.HTTPSConnection(\"v3.football.api-sports.io\")\n",
    "    return conn\n",
    "\n",
    "# Cache for API responses to avoid duplicate calls\n",
    "CACHE = {}\n",
    "\n",
    "#####################\n",
    "# 1. HELPER FUNCTIONS\n",
    "#####################\n",
    "\n",
    "@lru_cache(maxsize=1000)\n",
    "def do_api_call(endpoint):\n",
    "    \"\"\"\n",
    "    Makes an HTTPS request to `endpoint`, parses JSON, and returns it.\n",
    "    Uses LRU cache to avoid duplicate calls and implements retry logic.\n",
    "    \"\"\"\n",
    "    # Check if in cache\n",
    "    if endpoint in CACHE:\n",
    "        return CACHE[endpoint]\n",
    "    \n",
    "    conn = create_connection()\n",
    "    headers = {\n",
    "        \"x-rapidapi-host\": \"v3.football.api-sports.io\",\n",
    "        \"x-rapidapi-key\": API_KEY\n",
    "    }\n",
    "    \n",
    "    for attempt in range(MAX_RETRIES):\n",
    "        try:\n",
    "            conn.request(\"GET\", endpoint, headers=headers)\n",
    "            res = conn.getresponse()\n",
    "            data = res.read()\n",
    "            \n",
    "            # Check if rate limited (status code 429)\n",
    "            if res.status == 429:\n",
    "                wait_time = RETRY_WAIT_SECONDS * (2 ** attempt)  # Exponential backoff\n",
    "                print(f\"Rate limited. Waiting {wait_time}s before retry {attempt+1}\")\n",
    "                time.sleep(wait_time)\n",
    "                continue\n",
    "                \n",
    "            # Attempt to parse JSON\n",
    "            json_data = json.loads(data.decode(\"utf-8\"))\n",
    "            \n",
    "            # Cache the result\n",
    "            CACHE[endpoint] = json_data\n",
    "            return json_data\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error on attempt {attempt+1} for endpoint {endpoint}: {e}\")\n",
    "            if attempt < MAX_RETRIES - 1:\n",
    "                # Exponential backoff\n",
    "                wait_time = RETRY_WAIT_SECONDS * (2 ** attempt)\n",
    "                time.sleep(wait_time)\n",
    "            else:\n",
    "                print(f\"Max retries reached for {endpoint}. Giving up.\")\n",
    "                return None\n",
    "    \n",
    "    return None\n",
    "\n",
    "def get_player_stats_for_fixture(fixture_id, player_id):\n",
    "    \"\"\"Get stats for a specific player in a fixture\"\"\"\n",
    "    if fixture_id is None:\n",
    "        return None\n",
    "\n",
    "    endpoint = f\"/fixtures/players?fixture={fixture_id}\"\n",
    "    json_data = do_api_call(endpoint)\n",
    "    if not json_data:\n",
    "        return None\n",
    "    \n",
    "    # Go through the response to find player stats\n",
    "    for team_info in json_data.get(\"response\", []):\n",
    "        players = team_info.get(\"players\", [])\n",
    "        for p in players:\n",
    "            if p[\"player\"][\"id\"] == player_id:\n",
    "                return p[\"statistics\"][0] if p[\"statistics\"] else None\n",
    "    return None\n",
    "\n",
    "def get_team_stats_for_fixture(fixture_id, team_id):\n",
    "    \"\"\"Get team statistics for a specific fixture\"\"\"\n",
    "    if fixture_id is None or team_id is None:\n",
    "        return None\n",
    "\n",
    "    endpoint = f\"/fixtures/statistics?fixture={fixture_id}&team={team_id}\"\n",
    "    json_data = do_api_call(endpoint)\n",
    "    if not json_data or not json_data.get(\"response\"):\n",
    "        return None\n",
    "    \n",
    "    team_stats_obj = json_data[\"response\"][0]\n",
    "    raw_stats = team_stats_obj.get(\"statistics\", [])\n",
    "    stats_dict = {}\n",
    "    for stat_item in raw_stats:\n",
    "        key = stat_item[\"type\"]\n",
    "        val = stat_item[\"value\"]\n",
    "        key_norm = key.lower().replace(\" \", \"_\")\n",
    "        stats_dict[key_norm] = val\n",
    "    return stats_dict\n",
    "\n",
    "#####################\n",
    "# 2. PARALLEL PROCESSING\n",
    "#####################\n",
    "\n",
    "def process_row(row):\n",
    "    \"\"\"Process a single row in parallel\"\"\"\n",
    "    player_id = row[\"injury_player_id\"]\n",
    "    NUM_PREV_FIXTURES = 5\n",
    "    \n",
    "    # Prepare lists to hold results\n",
    "    player_team_stats_list = []\n",
    "    team_agg_stats_list = []\n",
    "    opp_team_stats_list = []\n",
    "    \n",
    "    # Collect all tasks we need to run\n",
    "    tasks = []\n",
    "    \n",
    "    # Player's own team last 5 fixtures\n",
    "    for i in range(1, NUM_PREV_FIXTURES+1):\n",
    "        fix_id_col = f\"prev_inj_team_fixture_{i}\"\n",
    "        fix_id = row[fix_id_col]\n",
    "        if fix_id:\n",
    "            # Add player stats task\n",
    "            tasks.append({\n",
    "                'type': 'player',\n",
    "                'fixture_id': fix_id,\n",
    "                'player_id': player_id,\n",
    "                'index': i-1\n",
    "            })\n",
    "            \n",
    "            # Add team stats task\n",
    "            tasks.append({\n",
    "                'type': 'team',\n",
    "                'fixture_id': fix_id,\n",
    "                'team_id': row[\"injury_team_id\"],\n",
    "                'index': i-1\n",
    "            })\n",
    "    \n",
    "    # Opponent's last 5 fixtures\n",
    "    for i in range(1, NUM_PREV_FIXTURES+1):\n",
    "        fix_id_col = f\"prev_opp_team_fixture_{i}\"\n",
    "        fix_id = row[fix_id_col]\n",
    "        if fix_id:\n",
    "            # Add opponent stats task\n",
    "            tasks.append({\n",
    "                'type': 'opponent',\n",
    "                'fixture_id': fix_id,\n",
    "                'team_id': row[\"opponent_team_id\"],\n",
    "                'index': i-1\n",
    "            })\n",
    "    \n",
    "    # Initialize result lists with None placeholders\n",
    "    player_team_stats_list = [None] * NUM_PREV_FIXTURES\n",
    "    team_agg_stats_list = [None] * NUM_PREV_FIXTURES\n",
    "    opp_team_stats_list = [None] * NUM_PREV_FIXTURES\n",
    "    \n",
    "    # Execute all tasks (in a single thread since we're already in a worker)\n",
    "    for task in tasks:\n",
    "        if task['type'] == 'player':\n",
    "            result = get_player_stats_for_fixture(task['fixture_id'], task['player_id'])\n",
    "            player_team_stats_list[task['index']] = result\n",
    "        elif task['type'] == 'team':\n",
    "            result = get_team_stats_for_fixture(task['fixture_id'], task['team_id'])\n",
    "            team_agg_stats_list[task['index']] = result\n",
    "        elif task['type'] == 'opponent':\n",
    "            result = get_team_stats_for_fixture(task['fixture_id'], task['team_id'])\n",
    "            opp_team_stats_list[task['index']] = result\n",
    "    \n",
    "    return {\n",
    "        'player_team_fixture_stats': player_team_stats_list,\n",
    "        'team_fixture_agg_stats': team_agg_stats_list,\n",
    "        'opp_fixture_agg_stats': opp_team_stats_list\n",
    "    }\n",
    "\n",
    "def batch_process_rows(df):\n",
    "    \"\"\"Process all rows in parallel\"\"\"\n",
    "    all_results = []\n",
    "    \n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "        # Create a mapping of future to row index\n",
    "        future_to_idx = {\n",
    "            executor.submit(process_row, row): idx \n",
    "            for idx, row in df.iterrows()\n",
    "        }\n",
    "        \n",
    "        # Process as they complete\n",
    "        for future in tqdm(concurrent.futures.as_completed(future_to_idx), \n",
    "                          total=len(future_to_idx),\n",
    "                          desc=\"Processing rows\"):\n",
    "            idx = future_to_idx[future]\n",
    "            try:\n",
    "                result = future.result()\n",
    "                all_results.append((idx, result))\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing row {idx}: {e}\")\n",
    "                all_results.append((idx, None))\n",
    "    \n",
    "    # Sort results by original index\n",
    "    all_results.sort(key=lambda x: x[0])\n",
    "    \n",
    "    # Extract results in correct order\n",
    "    player_team_fixture_stats = []\n",
    "    team_fixture_agg_stats = []\n",
    "    opp_fixture_agg_stats = []\n",
    "    \n",
    "    for _, result in all_results:\n",
    "        if result:\n",
    "            player_team_fixture_stats.append(result['player_team_fixture_stats'])\n",
    "            team_fixture_agg_stats.append(result['team_fixture_agg_stats'])\n",
    "            opp_fixture_agg_stats.append(result['opp_fixture_agg_stats'])\n",
    "        else:\n",
    "            # Handle error case\n",
    "            player_team_fixture_stats.append([None] * 5)\n",
    "            team_fixture_agg_stats.append([None] * 5)\n",
    "            opp_fixture_agg_stats.append([None] * 5)\n",
    "    \n",
    "    return player_team_fixture_stats, team_fixture_agg_stats, opp_fixture_agg_stats\n",
    "\n",
    "#####################\n",
    "# 3. MAIN EXECUTION\n",
    "#####################\n",
    "\n",
    "def main():\n",
    "    print(\"Existing columns in df:\", df.columns)\n",
    "    \n",
    "    # Process all rows in parallel\n",
    "    print(\"Starting parallel processing of API calls...\")\n",
    "    player_team_fixture_stats, team_fixture_agg_stats, opp_fixture_agg_stats = batch_process_rows(df)\n",
    "    \n",
    "    # Now store them in new columns\n",
    "    df[\"raw_player_team_fixture_stats\"] = player_team_fixture_stats\n",
    "    df[\"raw_team_fixture_agg_stats\"] = team_fixture_agg_stats\n",
    "    df[\"raw_opp_fixture_agg_stats\"] = opp_fixture_agg_stats\n",
    "    \n",
    "    print(\"\\nStage 1 complete! df now has raw data columns:\")\n",
    "    print(df[[\"raw_player_team_fixture_stats\", \n",
    "              \"raw_team_fixture_agg_stats\",\n",
    "              \"raw_opp_fixture_agg_stats\"]].head())\n",
    "    \n",
    "    # Print cache stats\n",
    "    print(f\"Cache hits: {do_api_call.cache_info().hits}\")\n",
    "    print(f\"Cache misses: {do_api_call.cache_info().misses}\")\n",
    "    print(f\"Cache size: {len(CACHE)} entries\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T17:10:42.082198Z",
     "iopub.status.busy": "2025-04-08T17:10:42.081749Z",
     "iopub.status.idle": "2025-04-08T17:10:42.169214Z",
     "shell.execute_reply": "2025-04-08T17:10:42.167997Z",
     "shell.execute_reply.started": "2025-04-08T17:10:42.082167Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"stage1.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregate the Raw Features and Derive More Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T17:10:49.615357Z",
     "iopub.status.busy": "2025-04-08T17:10:49.615017Z",
     "iopub.status.idle": "2025-04-08T17:10:52.804643Z",
     "shell.execute_reply": "2025-04-08T17:10:52.803215Z",
     "shell.execute_reply.started": "2025-04-08T17:10:49.615331Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-63-591dcbe21eca>:136: RuntimeWarning: Mean of empty slice\n",
      "  pass_acc_mean = np.nanmean(passes_accuracy_list)  # average across matches\n",
      "<ipython-input-63-591dcbe21eca>:140: RuntimeWarning: Mean of empty slice\n",
      "  \"player_minutes_avg_5\":           np.nanmean(minutes_list),\n",
      "<ipython-input-63-591dcbe21eca>:141: RuntimeWarning: Mean of empty slice\n",
      "  \"player_rating_avg_5\":            np.nanmean(rating_list),\n",
      "<ipython-input-63-591dcbe21eca>:293: RuntimeWarning: Mean of empty slice\n",
      "  \"opp_ball_poss_avg_5\":   np.nanmean(ball_poss_list),\n",
      "<ipython-input-63-591dcbe21eca>:227: RuntimeWarning: Mean of empty slice\n",
      "  \"team_ball_poss_avg_5\":    np.nanmean(ball_poss_list),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final feature columns for modeling:\n",
      "['injuried', 'prev_player_age', 'prev_player_height', 'prev_player_weight', 'prev_games_appearences', 'prev_games_lineups', 'prev_games_minutes', 'prev_games_number', 'prev_games_position', 'prev_games_rating', 'prev_games_captain', 'prev_substitutes_in', 'prev_substitutes_out', 'prev_substitutes_bench', 'prev_shots_total', 'prev_shots_on', 'prev_goals_total', 'prev_goals_conceded', 'prev_goals_assists', 'prev_goals_saves', 'prev_passes_total', 'prev_passes_key', 'prev_passes_accuracy', 'prev_tackles_total', 'prev_tackles_blocks', 'prev_tackles_interceptions', 'prev_duels_total', 'prev_duels_won', 'prev_dribbles_attempts', 'prev_dribbles_success', 'prev_dribbles_past', 'prev_fouls_drawn', 'prev_fouls_committed', 'prev_cards_yellow', 'prev_cards_yellowred', 'prev_cards_red', 'prev_penalty_won', 'prev_penalty_commited', 'prev_penalty_scored', 'prev_penalty_missed', 'prev_penalty_saved', 'player_minutes_avg_5', 'player_rating_avg_5', 'player_shots_total_5', 'player_shots_on_5', 'player_goals_5', 'player_assists_5', 'player_fouls_committed_5', 'player_fouls_drawn_5', 'player_yellow_cards_5', 'player_red_cards_5', 'player_duels_total_5', 'player_duels_won_5', 'player_passes_total_5', 'player_passes_key_5', 'player_tackles_total_5', 'player_tackles_blocks_5', 'player_tackles_interceptions_5', 'player_duels_win_ratio_5', 'player_pass_acc_mean_5', 'team_shots_on_goal_5', 'team_shots_off_goal_5', 'team_total_shots_5', 'team_fouls_5', 'team_corners_5', 'team_offsides_5', 'team_ball_poss_avg_5', 'team_yellow_cards_5', 'team_red_cards_5', 'team_passes_5', 'team_passes_acc_5', 'team_pass_acc_ratio_5', 'opp_shots_on_goal_5', 'opp_shots_off_goal_5', 'opp_total_shots_5', 'opp_fouls_5', 'opp_corners_5', 'opp_offsides_5', 'opp_ball_poss_avg_5', 'opp_yellow_cards_5', 'opp_red_cards_5', 'opp_passes_5', 'opp_passes_acc_5', 'opp_pass_acc_ratio_5', 'days_since_last_injury', 'inj_count_last_6m', 'team_vs_opp_shots_diff_5', 'team_vs_opp_sog_diff_5', 'team_vs_opp_fouls_diff_5', 'team_vs_opp_corners_diff_5', 'team_vs_opp_offsides_diff_5', 'team_vs_opp_poss_diff_5', 'team_vs_opp_pass_acc_diff_5', 'team_vs_opp_shots_ratio_5', 'team_vs_opp_sog_ratio_5', 'team_vs_opp_fouls_ratio_5', 'team_vs_opp_corners_ratio_5', 'team_vs_opp_offsides_ratio_5', 'team_vs_opp_poss_ratio_5', 'team_vs_opp_pass_acc_ratio_5']\n",
      "Sample of final features:\n",
      "   injuried  prev_player_age prev_player_height prev_player_weight  \\\n",
      "0         1               31             189 cm              77 kg   \n",
      "1         1               31             189 cm              77 kg   \n",
      "2         1               31             189 cm              77 kg   \n",
      "3         1               31             189 cm              77 kg   \n",
      "4         1               34             184 cm              70 kg   \n",
      "5         1               34             184 cm              70 kg   \n",
      "6         1               34             184 cm              70 kg   \n",
      "7         1               34             184 cm              70 kg   \n",
      "8         1               34             184 cm              70 kg   \n",
      "9         1               29             184 cm              78 kg   \n",
      "\n",
      "   prev_games_appearences  prev_games_lineups  prev_games_minutes  \\\n",
      "0                    33.0                33.0              2939.0   \n",
      "1                    33.0                33.0              2939.0   \n",
      "2                    33.0                33.0              2939.0   \n",
      "3                    33.0                33.0              2939.0   \n",
      "4                     3.0                 3.0               226.0   \n",
      "5                     3.0                 3.0               226.0   \n",
      "6                     3.0                 3.0               226.0   \n",
      "7                     3.0                 3.0               226.0   \n",
      "8                     3.0                 3.0               226.0   \n",
      "9                    29.0                22.0              2047.0   \n",
      "\n",
      "   prev_games_number prev_games_position  prev_games_rating  ...  \\\n",
      "0                NaN          Goalkeeper           6.969696  ...   \n",
      "1                NaN          Goalkeeper           6.969696  ...   \n",
      "2                NaN          Goalkeeper           6.969696  ...   \n",
      "3                NaN          Goalkeeper           6.969696  ...   \n",
      "4                NaN            Defender           6.566666  ...   \n",
      "5                NaN            Defender           6.566666  ...   \n",
      "6                NaN            Defender           6.566666  ...   \n",
      "7                NaN            Defender           6.566666  ...   \n",
      "8                NaN            Defender           6.566666  ...   \n",
      "9                NaN            Defender           7.292857  ...   \n",
      "\n",
      "   team_vs_opp_offsides_diff_5  team_vs_opp_poss_diff_5  \\\n",
      "0                          3.0                      NaN   \n",
      "1                          0.0                      NaN   \n",
      "2                          0.0                11.000000   \n",
      "3                          1.0                25.500000   \n",
      "4                         -3.0                -3.500000   \n",
      "5                          2.0                11.500000   \n",
      "6                         -1.0                24.666667   \n",
      "7                          5.0                 9.666667   \n",
      "8                          5.0                      NaN   \n",
      "9                          1.0                23.000000   \n",
      "\n",
      "   team_vs_opp_pass_acc_diff_5  team_vs_opp_shots_ratio_5  \\\n",
      "0                          NaN                        NaN   \n",
      "1                          NaN                        NaN   \n",
      "2                     0.083478                   1.363636   \n",
      "3                     0.127389                   4.142857   \n",
      "4                    -0.054842                   2.235294   \n",
      "5                     0.110353                   3.100000   \n",
      "6                     0.264349                   5.000000   \n",
      "7                     0.069787                   3.750000   \n",
      "8                          NaN                        NaN   \n",
      "9                     0.103172                   1.555556   \n",
      "\n",
      "   team_vs_opp_sog_ratio_5  team_vs_opp_fouls_ratio_5  \\\n",
      "0                      NaN                        NaN   \n",
      "1                      NaN                        NaN   \n",
      "2                 1.166667                   1.583333   \n",
      "3                 3.250000                   2.066667   \n",
      "4                 1.777778                   2.600000   \n",
      "5                 1.800000                   2.454545   \n",
      "6                 7.000000                   3.166667   \n",
      "7                 4.666667                   2.235294   \n",
      "8                      NaN                        NaN   \n",
      "9                 1.000000                   1.800000   \n",
      "\n",
      "   team_vs_opp_corners_ratio_5  team_vs_opp_offsides_ratio_5  \\\n",
      "0                          NaN                           NaN   \n",
      "1                          NaN                           NaN   \n",
      "2                     3.500000                           NaN   \n",
      "3                     3.250000                      1.500000   \n",
      "4                     2.200000                      0.250000   \n",
      "5                     3.000000                      3.000000   \n",
      "6                     3.333333                      0.833333   \n",
      "7                     6.666667                           NaN   \n",
      "8                          NaN                           NaN   \n",
      "9                          NaN                           NaN   \n",
      "\n",
      "   team_vs_opp_poss_ratio_5  team_vs_opp_pass_acc_ratio_5  \n",
      "0                       NaN                           NaN  \n",
      "1                       NaN                           NaN  \n",
      "2                  1.207547                      1.102213  \n",
      "3                  1.653846                      1.167544  \n",
      "4                  0.945312                      0.940172  \n",
      "5                  1.287500                      1.148003  \n",
      "6                  1.795699                      1.442100  \n",
      "7                  1.210145                      1.088059  \n",
      "8                       NaN                           NaN  \n",
      "9                  1.741935                      1.138519  \n",
      "\n",
      "[10 rows x 100 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n",
      "  has_large_values = (abs_vals > 1e6).any()\n",
      "/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n",
      "/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n"
     ]
    }
   ],
   "source": [
    "#########################\n",
    "# STAGE 2: FEATURE ENGINEERING\n",
    "#########################\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "########################################################\n",
    "# 0) Rename Columns if Needed\n",
    "########################################################\n",
    "# Suppose your main DataFrame is called df and currently has columns like:\n",
    "#  [\"injury_player_id\", \"injury_date\", \"fixture_id\", \"injury_team_id\", ...]\n",
    "# But we want to rename them to simpler names: \"player_id\", \"date\", \"team_id\", ...\n",
    "# so the code below is consistent.\n",
    "\n",
    "df = df.rename(columns={\n",
    "    \"injury_player_id\": \"player_id\",\n",
    "    \"injury_date\": \"date\",\n",
    "    \"injury_team_id\": \"team_id\",\n",
    "    \"injury_league_id\": \"league_id\",\n",
    "})\n",
    "\n",
    "# The same if your injuries DataFrame has those columns:\n",
    "df_injuries = df[[\"player_id\",\"date\",\"reason\",\"injuried\"]].copy()\n",
    "\n",
    "########################################################\n",
    "# 1) Helpers for Parsing and Safe Operations\n",
    "########################################################\n",
    "\n",
    "def safe_float(x):\n",
    "    \"\"\"Convert x to float or return np.nan if not possible.\"\"\"\n",
    "    try:\n",
    "        return float(x)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def safe_int(x):\n",
    "    \"\"\"Convert x to int or return np.nan if not possible.\"\"\"\n",
    "    try:\n",
    "        return int(x)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "########################################################\n",
    "# 2) Aggregators for Player Stats\n",
    "########################################################\n",
    "\n",
    "def aggregate_player_stats(stats_list):\n",
    "    \"\"\"\n",
    "    stats_list is a list of up to 5 dicts, each representing\n",
    "    the player's stats for one fixture (from 'raw_player_team_fixture_stats').\n",
    "    We'll sum or average relevant fields across these fixtures.\n",
    "    \"\"\"\n",
    "    minutes_list, rating_list = [], []\n",
    "\n",
    "    shots_total_list, shots_on_list = [], []\n",
    "    goals_total_list, assists_list = [], []\n",
    "    fouls_committed_list, fouls_drawn_list = [], []\n",
    "    yellow_cards_list, red_cards_list = [], []\n",
    "    duels_total_list, duels_won_list = [], []\n",
    "    \n",
    "    passes_total_list, passes_key_list, passes_accuracy_list = [], [], []\n",
    "    tackles_total_list, tackles_blocks_list, tackles_interceptions_list = [], [], []\n",
    "    \n",
    "    for st in stats_list:\n",
    "        if not st:\n",
    "            # No stats => fill with NaN placeholders\n",
    "            minutes_list.append(np.nan)\n",
    "            rating_list.append(np.nan)\n",
    "\n",
    "            shots_total_list.append(np.nan)\n",
    "            shots_on_list.append(np.nan)\n",
    "            goals_total_list.append(np.nan)\n",
    "            assists_list.append(np.nan)\n",
    "\n",
    "            fouls_committed_list.append(np.nan)\n",
    "            fouls_drawn_list.append(np.nan)\n",
    "            yellow_cards_list.append(np.nan)\n",
    "            red_cards_list.append(np.nan)\n",
    "\n",
    "            duels_total_list.append(np.nan)\n",
    "            duels_won_list.append(np.nan)\n",
    "\n",
    "            passes_total_list.append(np.nan)\n",
    "            passes_key_list.append(np.nan)\n",
    "            passes_accuracy_list.append(np.nan)\n",
    "\n",
    "            tackles_total_list.append(np.nan)\n",
    "            tackles_blocks_list.append(np.nan)\n",
    "            tackles_interceptions_list.append(np.nan)\n",
    "        else:\n",
    "            g = st.get(\"games\", {})\n",
    "            minutes_list.append(safe_float(g.get(\"minutes\", np.nan)))\n",
    "            rating_list.append(safe_float(g.get(\"rating\", np.nan)))  # often a string, e.g. \"7.5\"\n",
    "\n",
    "            s = st.get(\"shots\", {})\n",
    "            shots_total_list.append(safe_float(s.get(\"total\", np.nan)))\n",
    "            shots_on_list.append(safe_float(s.get(\"on\", np.nan)))\n",
    "\n",
    "            gl = st.get(\"goals\", {})\n",
    "            goals_total_list.append(safe_float(gl.get(\"total\", np.nan)))\n",
    "            assists_list.append(safe_float(gl.get(\"assists\", np.nan)))\n",
    "\n",
    "            f = st.get(\"fouls\", {})\n",
    "            fouls_committed_list.append(safe_float(f.get(\"committed\", np.nan)))\n",
    "            fouls_drawn_list.append(safe_float(f.get(\"drawn\", np.nan)))\n",
    "\n",
    "            c = st.get(\"cards\", {})\n",
    "            yellow_cards_list.append(safe_float(c.get(\"yellow\", np.nan)))\n",
    "            red_cards_list.append(safe_float(c.get(\"red\", np.nan)))\n",
    "\n",
    "            d = st.get(\"duels\", {})\n",
    "            duels_total_list.append(safe_float(d.get(\"total\", np.nan)))\n",
    "            duels_won_list.append(safe_float(d.get(\"won\", np.nan)))\n",
    "\n",
    "            p = st.get(\"passes\", {})\n",
    "            passes_total_list.append(safe_float(p.get(\"total\", np.nan)))\n",
    "            passes_key_list.append(safe_float(p.get(\"key\", np.nan)))\n",
    "            passes_accuracy_list.append(safe_float(p.get(\"accuracy\", np.nan)))\n",
    "\n",
    "            t = st.get(\"tackles\", {})\n",
    "            tackles_total_list.append(safe_float(t.get(\"total\", np.nan)))\n",
    "            tackles_blocks_list.append(safe_float(t.get(\"blocks\", np.nan)))\n",
    "            tackles_interceptions_list.append(safe_float(t.get(\"interceptions\", np.nan)))\n",
    "\n",
    "    # Summations\n",
    "    shots_total_5 = np.nansum(shots_total_list)\n",
    "    duels_total_5 = np.nansum(duels_total_list)\n",
    "\n",
    "    # Ratio example: duels won\n",
    "    duels_win_ratio_5 = np.nan\n",
    "    if duels_total_5 > 0:\n",
    "        duels_win_ratio_5 = np.nansum(duels_won_list) / duels_total_5\n",
    "\n",
    "    # Pass accuracy example\n",
    "    pass_acc_mean = np.nanmean(passes_accuracy_list)  # average across matches\n",
    "\n",
    "    features = {\n",
    "        # Averages\n",
    "        \"player_minutes_avg_5\":           np.nanmean(minutes_list),\n",
    "        \"player_rating_avg_5\":            np.nanmean(rating_list),\n",
    "\n",
    "        # Sums\n",
    "        \"player_shots_total_5\":           shots_total_5,\n",
    "        \"player_shots_on_5\":             np.nansum(shots_on_list),\n",
    "        \"player_goals_5\":                 np.nansum(goals_total_list),\n",
    "        \"player_assists_5\":               np.nansum(assists_list),\n",
    "        \"player_fouls_committed_5\":       np.nansum(fouls_committed_list),\n",
    "        \"player_fouls_drawn_5\":           np.nansum(fouls_drawn_list),\n",
    "        \"player_yellow_cards_5\":          np.nansum(yellow_cards_list),\n",
    "        \"player_red_cards_5\":             np.nansum(red_cards_list),\n",
    "        \"player_duels_total_5\":           duels_total_5,\n",
    "        \"player_duels_won_5\":             np.nansum(duels_won_list),\n",
    "        \"player_passes_total_5\":          np.nansum(passes_total_list),\n",
    "        \"player_passes_key_5\":            np.nansum(passes_key_list),\n",
    "        \"player_tackles_total_5\":         np.nansum(tackles_total_list),\n",
    "        \"player_tackles_blocks_5\":        np.nansum(tackles_blocks_list),\n",
    "        \"player_tackles_interceptions_5\": np.nansum(tackles_interceptions_list),\n",
    "\n",
    "        # Ratios\n",
    "        \"player_duels_win_ratio_5\":       duels_win_ratio_5,\n",
    "        \"player_pass_acc_mean_5\":         pass_acc_mean,\n",
    "    }\n",
    "\n",
    "    return features\n",
    "\n",
    "########################################################\n",
    "# 3) Aggregators for Team & Opponent Stats\n",
    "########################################################\n",
    "\n",
    "def aggregate_team_stats(stats_list):\n",
    "    sog_list, sof_list, total_shots_list = [], [], []\n",
    "    fouls_list, corners_list, offsides_list = [], [], []\n",
    "    ball_poss_list = []\n",
    "    yellow_cards_list, red_cards_list = [], []\n",
    "    passes_list, passes_accurate_list = [], []\n",
    "\n",
    "    for st in stats_list:\n",
    "        if not st:\n",
    "            sog_list.append(np.nan)\n",
    "            sof_list.append(np.nan)\n",
    "            total_shots_list.append(np.nan)\n",
    "            fouls_list.append(np.nan)\n",
    "            corners_list.append(np.nan)\n",
    "            offsides_list.append(np.nan)\n",
    "            ball_poss_list.append(np.nan)\n",
    "            yellow_cards_list.append(np.nan)\n",
    "            red_cards_list.append(np.nan)\n",
    "            passes_list.append(np.nan)\n",
    "            passes_accurate_list.append(np.nan)\n",
    "        else:\n",
    "            sog_list.append(safe_float(st.get(\"shots_on_goal\", np.nan)))\n",
    "            sof_list.append(safe_float(st.get(\"shots_off_goal\", np.nan)))\n",
    "            total_shots_list.append(safe_float(st.get(\"total_shots\", np.nan)))\n",
    "            fouls_list.append(safe_float(st.get(\"fouls\", np.nan)))\n",
    "            corners_list.append(safe_float(st.get(\"corner_kicks\", np.nan)))\n",
    "            offsides_list.append(safe_float(st.get(\"offsides\", np.nan)))\n",
    "\n",
    "            poss_str = st.get(\"ball_possession\", None)\n",
    "            if poss_str and isinstance(poss_str, str) and poss_str.endswith(\"%\"):\n",
    "                val = poss_str.replace(\"%\", \"\")\n",
    "                ball_poss_list.append(safe_float(val))\n",
    "            else:\n",
    "                ball_poss_list.append(np.nan)\n",
    "\n",
    "            yellow_cards_list.append(safe_float(st.get(\"yellow_cards\", np.nan)))\n",
    "            red_cards_list.append(safe_float(st.get(\"red_cards\", np.nan)))\n",
    "\n",
    "            passes_list.append(safe_float(st.get(\"total_passes\", np.nan)))\n",
    "            passes_accurate_list.append(safe_float(st.get(\"passes_accurate\", np.nan)))\n",
    "\n",
    "    sog_sum = np.nansum(sog_list)\n",
    "    passes_sum = np.nansum(passes_list)\n",
    "    passes_acc_sum = np.nansum(passes_accurate_list)\n",
    "\n",
    "    pass_accuracy_5 = np.nan\n",
    "    if passes_sum > 0:\n",
    "        pass_accuracy_5 = passes_acc_sum / passes_sum\n",
    "\n",
    "    features = {\n",
    "        \"team_shots_on_goal_5\":    sog_sum,\n",
    "        \"team_shots_off_goal_5\":   np.nansum(sof_list),\n",
    "        \"team_total_shots_5\":      np.nansum(total_shots_list),\n",
    "        \"team_fouls_5\":            np.nansum(fouls_list),\n",
    "        \"team_corners_5\":          np.nansum(corners_list),\n",
    "        \"team_offsides_5\":         np.nansum(offsides_list),\n",
    "        \"team_ball_poss_avg_5\":    np.nanmean(ball_poss_list),\n",
    "        \"team_yellow_cards_5\":     np.nansum(yellow_cards_list),\n",
    "        \"team_red_cards_5\":        np.nansum(red_cards_list),\n",
    "        \"team_passes_5\":           passes_sum,\n",
    "        \"team_passes_acc_5\":       passes_acc_sum,\n",
    "        \"team_pass_acc_ratio_5\":   pass_accuracy_5,\n",
    "    }\n",
    "    return features\n",
    "\n",
    "\n",
    "def aggregate_opponent_stats(stats_list):\n",
    "    sog_list, sof_list, total_shots_list = [], [], []\n",
    "    fouls_list, corners_list, offsides_list = [], [], []\n",
    "    ball_poss_list = []\n",
    "    yellow_cards_list, red_cards_list = [], []\n",
    "    passes_list, passes_accurate_list = [], []\n",
    "\n",
    "    for st in stats_list:\n",
    "        if not st:\n",
    "            sog_list.append(np.nan)\n",
    "            sof_list.append(np.nan)\n",
    "            total_shots_list.append(np.nan)\n",
    "            fouls_list.append(np.nan)\n",
    "            corners_list.append(np.nan)\n",
    "            offsides_list.append(np.nan)\n",
    "            ball_poss_list.append(np.nan)\n",
    "            yellow_cards_list.append(np.nan)\n",
    "            red_cards_list.append(np.nan)\n",
    "            passes_list.append(np.nan)\n",
    "            passes_accurate_list.append(np.nan)\n",
    "        else:\n",
    "            sog_list.append(safe_float(st.get(\"shots_on_goal\", np.nan)))\n",
    "            sof_list.append(safe_float(st.get(\"shots_off_goal\", np.nan)))\n",
    "            total_shots_list.append(safe_float(st.get(\"total_shots\", np.nan)))\n",
    "            fouls_list.append(safe_float(st.get(\"fouls\", np.nan)))\n",
    "            corners_list.append(safe_float(st.get(\"corner_kicks\", np.nan)))\n",
    "            offsides_list.append(safe_float(st.get(\"offsides\", np.nan)))\n",
    "\n",
    "            poss_str = st.get(\"ball_possession\", None)\n",
    "            if poss_str and isinstance(poss_str, str) and poss_str.endswith(\"%\"):\n",
    "                val = poss_str.replace(\"%\", \"\")\n",
    "                ball_poss_list.append(safe_float(val))\n",
    "            else:\n",
    "                ball_poss_list.append(np.nan)\n",
    "\n",
    "            yellow_cards_list.append(safe_float(st.get(\"yellow_cards\", np.nan)))\n",
    "            red_cards_list.append(safe_float(st.get(\"red_cards\", np.nan)))\n",
    "\n",
    "            passes_list.append(safe_float(st.get(\"total_passes\", np.nan)))\n",
    "            passes_accurate_list.append(safe_float(st.get(\"passes_accurate\", np.nan)))\n",
    "\n",
    "    sog_sum = np.nansum(sog_list)\n",
    "    passes_sum = np.nansum(passes_list)\n",
    "    passes_acc_sum = np.nansum(passes_accurate_list)\n",
    "\n",
    "    pass_accuracy_5 = np.nan\n",
    "    if passes_sum > 0:\n",
    "        pass_accuracy_5 = passes_acc_sum / passes_sum\n",
    "\n",
    "    features = {\n",
    "        \"opp_shots_on_goal_5\":   sog_sum,\n",
    "        \"opp_shots_off_goal_5\":  np.nansum(sof_list),\n",
    "        \"opp_total_shots_5\":     np.nansum(total_shots_list),\n",
    "        \"opp_fouls_5\":           np.nansum(fouls_list),\n",
    "        \"opp_corners_5\":         np.nansum(corners_list),\n",
    "        \"opp_offsides_5\":        np.nansum(offsides_list),\n",
    "        \"opp_ball_poss_avg_5\":   np.nanmean(ball_poss_list),\n",
    "        \"opp_yellow_cards_5\":    np.nansum(yellow_cards_list),\n",
    "        \"opp_red_cards_5\":       np.nansum(red_cards_list),\n",
    "        \"opp_passes_5\":          passes_sum,\n",
    "        \"opp_passes_acc_5\":      passes_acc_sum,\n",
    "        \"opp_pass_acc_ratio_5\":  pass_accuracy_5,\n",
    "    }\n",
    "    return features\n",
    "\n",
    "########################################################\n",
    "# 4) Days Since Last Injury (Optional)\n",
    "########################################################\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def compute_days_since_last_injury(df_main, df_injuries):\n",
    "    \"\"\"\n",
    "    Compute days since the last injury for each player in df_main.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df_main : pandas DataFrame\n",
    "        Main DataFrame containing player_id and date columns\n",
    "    df_injuries : pandas DataFrame\n",
    "        DataFrame containing injury records with player_id and date columns\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas DataFrame\n",
    "        Original df_main with added 'days_since_last_injury' column\n",
    "    \"\"\"\n",
    "    # Make a copy to avoid modifying the original\n",
    "    result_df = df_main.copy()\n",
    "    \n",
    "    # Convert date columns to datetime\n",
    "    result_df['date'] = pd.to_datetime(result_df['date'], errors='coerce')\n",
    "    injuries_df = df_injuries.copy()\n",
    "    injuries_df['date'] = pd.to_datetime(injuries_df['date'], errors='coerce')\n",
    "    \n",
    "    # Make sure player_id is consistent type\n",
    "    result_df['player_id'] = result_df['player_id'].astype(str)\n",
    "    injuries_df['player_id'] = injuries_df['player_id'].astype(str)\n",
    "    \n",
    "    # Create an empty column for days since last injury\n",
    "    result_df['days_since_last_injury'] = np.nan\n",
    "    \n",
    "    # Iterate through unique players\n",
    "    for player_id in result_df['player_id'].unique():\n",
    "        # Get all dates for this player\n",
    "        player_dates = result_df.loc[result_df['player_id'] == player_id, 'date']\n",
    "        if len(player_dates) == 0:\n",
    "            continue\n",
    "            \n",
    "        # Get all injury dates for this player\n",
    "        player_injury_dates = injuries_df.loc[injuries_df['player_id'] == player_id, 'date']\n",
    "        if len(player_injury_dates) == 0:\n",
    "            continue\n",
    "        \n",
    "        # For each date, find the most recent injury date before it\n",
    "        for idx, current_date in zip(player_dates.index, player_dates):\n",
    "            if pd.isna(current_date):\n",
    "                continue\n",
    "                \n",
    "            # Find most recent injury before current date\n",
    "            prior_injuries = player_injury_dates[player_injury_dates < current_date]\n",
    "            if len(prior_injuries) > 0:\n",
    "                most_recent_injury = max(prior_injuries)\n",
    "                days_since = (current_date - most_recent_injury).days\n",
    "                result_df.loc[idx, 'days_since_last_injury'] = days_since\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "########################################################\n",
    "# 5) Injuries in Last X Months (Optional)\n",
    "########################################################\n",
    "\n",
    "\n",
    "def compute_injuries_in_last_x_months(df_main, df_injuries, months=6):\n",
    "    \"\"\"\n",
    "    Count injuries in the last X months for each player in df_main.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df_main : pandas DataFrame\n",
    "        Main DataFrame containing player_id and date columns\n",
    "    df_injuries : pandas DataFrame\n",
    "        DataFrame containing injury records with player_id and date columns\n",
    "    months : int, default=6\n",
    "        Number of months to look back for injuries\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas DataFrame\n",
    "        Original df_main with added 'inj_count_last_Xm' column\n",
    "    \"\"\"\n",
    "    # Make a copy to avoid modifying the original\n",
    "    result_df = df_main.copy()\n",
    "    \n",
    "    # Convert date columns to datetime\n",
    "    result_df['date'] = pd.to_datetime(result_df['date'], errors='coerce')\n",
    "    injuries_df = df_injuries.copy()\n",
    "    injuries_df['date'] = pd.to_datetime(injuries_df['date'], errors='coerce')\n",
    "    \n",
    "    # Make sure player_id is consistent type\n",
    "    result_df['player_id'] = result_df['player_id'].astype(str)\n",
    "    injuries_df['player_id'] = injuries_df['player_id'].astype(str)\n",
    "    \n",
    "    # Create column name for injury count\n",
    "    count_col = f'inj_count_last_{months}m'\n",
    "    \n",
    "    # Initialize injury count column\n",
    "    result_df[count_col] = 0\n",
    "    \n",
    "    # Iterate through each row in the main dataframe\n",
    "    for idx, row in result_df.iterrows():\n",
    "        player_id = row['player_id']\n",
    "        current_date = row['date']\n",
    "        \n",
    "        if pd.isna(current_date):\n",
    "            result_df.loc[idx, count_col] = np.nan\n",
    "            continue\n",
    "            \n",
    "        # Define the time window\n",
    "        start_date = current_date - pd.DateOffset(months=months)\n",
    "        \n",
    "        # Count injuries in the window\n",
    "        count = len(injuries_df[(injuries_df['player_id'] == player_id) & \n",
    "                              (injuries_df['date'] >= start_date) & \n",
    "                              (injuries_df['date'] < current_date)])\n",
    "        \n",
    "        result_df.loc[idx, count_col] = count\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "########################################################\n",
    "# 6) Build All New Features from raw stats\n",
    "########################################################\n",
    "\n",
    "all_features_list = []\n",
    "for idx, row in df.iterrows():\n",
    "    # 1) player aggregator\n",
    "    p_feats = aggregate_player_stats(row[\"raw_player_team_fixture_stats\"])\n",
    "    \n",
    "    # 2) team aggregator\n",
    "    t_feats = aggregate_team_stats(row[\"raw_team_fixture_agg_stats\"])\n",
    "    \n",
    "    # 3) opponent aggregator\n",
    "    o_feats = aggregate_opponent_stats(row[\"raw_opp_fixture_agg_stats\"])\n",
    "    \n",
    "    # Combine them\n",
    "    combined = {}\n",
    "    combined.update(p_feats)\n",
    "    combined.update(t_feats)\n",
    "    combined.update(o_feats)\n",
    "    \n",
    "    all_features_list.append(combined)\n",
    "\n",
    "# Convert to a DataFrame\n",
    "features_df = pd.DataFrame(all_features_list)\n",
    "\n",
    "# Join these columns onto df\n",
    "df = pd.concat([df.reset_index(drop=True), features_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "########################################################\n",
    "# 7) Optionally, Add \"days_since_last_injury\" or \"injuries in last X months\"\n",
    "########################################################\n",
    "\n",
    "# If you have a separate injuries DataFrame called df_injuries with columns:\n",
    "#   [player_id, date, reason, etc. for each injury event]\n",
    "# Then do:\n",
    "\n",
    "df = compute_days_since_last_injury(df, df_injuries)\n",
    "df = compute_injuries_in_last_x_months(df, df_injuries, months=6)\n",
    "\n",
    "########################################################\n",
    "# 8) Additional Interactions (Team vs Opponent)\n",
    "########################################################\n",
    "# 1) Simple Differences\n",
    "df[\"team_vs_opp_shots_diff_5\"] = df[\"team_total_shots_5\"] - df[\"opp_total_shots_5\"]\n",
    "df[\"team_vs_opp_sog_diff_5\"] = df[\"team_shots_on_goal_5\"] - df[\"opp_shots_on_goal_5\"]\n",
    "df[\"team_vs_opp_fouls_diff_5\"] = df[\"team_fouls_5\"] - df[\"opp_fouls_5\"]\n",
    "df[\"team_vs_opp_corners_diff_5\"] = df[\"team_corners_5\"] - df[\"opp_corners_5\"]\n",
    "df[\"team_vs_opp_offsides_diff_5\"] = df[\"team_offsides_5\"] - df[\"opp_offsides_5\"]\n",
    "\n",
    "# Ball possession is an average in percent, so a difference here can show which side \n",
    "# tends to have a higher possession rating in recent matches.\n",
    "df[\"team_vs_opp_poss_diff_5\"] = df[\"team_ball_poss_avg_5\"] - df[\"opp_ball_poss_avg_5\"]\n",
    "\n",
    "# Pass accuracy ratio might also be an average or ratio. \n",
    "# But if you prefer to do difference of pass_acc_ratio_5:\n",
    "df[\"team_vs_opp_pass_acc_diff_5\"] = df[\"team_pass_acc_ratio_5\"] - df[\"opp_pass_acc_ratio_5\"]\n",
    "\n",
    "# 2) Ratios\n",
    "# For ratios, we use np.where() to avoid dividing by zero or NaN.\n",
    "\n",
    "df[\"team_vs_opp_shots_ratio_5\"] = np.where(\n",
    "    (df[\"opp_total_shots_5\"].isna()) | (df[\"opp_total_shots_5\"] == 0),\n",
    "    np.nan,\n",
    "    df[\"team_total_shots_5\"] / df[\"opp_total_shots_5\"]\n",
    ")\n",
    "\n",
    "df[\"team_vs_opp_sog_ratio_5\"] = np.where(\n",
    "    (df[\"opp_shots_on_goal_5\"].isna()) | (df[\"opp_shots_on_goal_5\"] == 0),\n",
    "    np.nan,\n",
    "    df[\"team_shots_on_goal_5\"] / df[\"opp_shots_on_goal_5\"]\n",
    ")\n",
    "\n",
    "df[\"team_vs_opp_fouls_ratio_5\"] = np.where(\n",
    "    (df[\"opp_fouls_5\"].isna()) | (df[\"opp_fouls_5\"] == 0),\n",
    "    np.nan,\n",
    "    df[\"team_fouls_5\"] / df[\"opp_fouls_5\"]\n",
    ")\n",
    "\n",
    "df[\"team_vs_opp_corners_ratio_5\"] = np.where(\n",
    "    (df[\"opp_corners_5\"].isna()) | (df[\"opp_corners_5\"] == 0),\n",
    "    np.nan,\n",
    "    df[\"team_corners_5\"] / df[\"opp_corners_5\"]\n",
    ")\n",
    "\n",
    "df[\"team_vs_opp_offsides_ratio_5\"] = np.where(\n",
    "    (df[\"opp_offsides_5\"].isna()) | (df[\"opp_offsides_5\"] == 0),\n",
    "    np.nan,\n",
    "    df[\"team_offsides_5\"] / df[\"opp_offsides_5\"]\n",
    ")\n",
    "\n",
    "# If you want a ratio for ball possession, e.g. how big is \n",
    "# your team's possession share relative to opponent's\n",
    "df[\"team_vs_opp_poss_ratio_5\"] = np.where(\n",
    "    (df[\"opp_ball_poss_avg_5\"].isna()) | (df[\"opp_ball_poss_avg_5\"] == 0),\n",
    "    np.nan,\n",
    "    df[\"team_ball_poss_avg_5\"] / df[\"opp_ball_poss_avg_5\"]\n",
    ")\n",
    "\n",
    "# Pass accuracy ratio (comparing your team's pass_acc_ratio_5 to opponent's)\n",
    "df[\"team_vs_opp_pass_acc_ratio_5\"] = np.where(\n",
    "    (df[\"opp_pass_acc_ratio_5\"].isna()) | (df[\"opp_pass_acc_ratio_5\"] == 0),\n",
    "    np.nan,\n",
    "    df[\"team_pass_acc_ratio_5\"] / df[\"opp_pass_acc_ratio_5\"]\n",
    ")\n",
    "\n",
    "########################################################\n",
    "# 9) Drop/Exclude ID Columns, Keep Features + Target\n",
    "########################################################\n",
    "# We'll assume your target is \"injuried\"\n",
    "# We'll exclude typical ID columns, plus raw stats columns if you want.\n",
    "\n",
    "exclude_cols = {\n",
    "    \"player_id\", \"fixture_id\", \"team_id\", \"league_id\", \"opponent_team_id\",\n",
    "    \"prev_inj_team_fixture_1\", \"prev_inj_team_fixture_2\", \"prev_inj_team_fixture_3\",\n",
    "    \"prev_inj_team_fixture_4\", \"prev_inj_team_fixture_5\",\n",
    "    \"prev_opp_team_fixture_1\", \"prev_opp_team_fixture_2\", \"prev_opp_team_fixture_3\",\n",
    "    \"prev_opp_team_fixture_4\", \"prev_opp_team_fixture_5\",\n",
    "    \"raw_player_team_fixture_stats\", \"raw_team_fixture_agg_stats\", \"raw_opp_fixture_agg_stats\",\n",
    "    \"date\",\n",
    "    'prev_player_id', 'prev_player_name', 'prev_player_firstname', 'prev_player_lastname', 'prev_player_birth_date', \n",
    "    'prev_player_birth_place', 'prev_player_birth_country', 'prev_player_nationality',\"prev_player_injured\",'prev_player_photo', \n",
    "    'prev_team_id', 'prev_team_name', 'prev_team_logo', 'prev_league_id', 'prev_league_name', 'prev_league_country', 'prev_league_logo', \n",
    "    'prev_league_flag', 'prev_league_season',\n",
    "    # \"inj_count_last_6m\",  # If you want to exclude or keep it, your choice\n",
    "    # If you want to exclude \"date\", you can add it here\n",
    "}\n",
    "\n",
    "all_cols = df.columns.tolist()\n",
    "final_cols = []\n",
    "for c in all_cols:\n",
    "    if c in exclude_cols:\n",
    "        continue\n",
    "    # Keep target \"injuried\" plus any that start with \"player_\", \"team_\", \"opp_\",\n",
    "    # or end with \"_diff_5\" or \"_ratio_5\", or \"days_since_last_injury\"\n",
    "    if (c == \"injuried\"\n",
    "        or c.startswith(\"player_\")\n",
    "        or c.startswith(\"team_\")\n",
    "        or c.startswith(\"opp_\")\n",
    "        or c.startswith(\"prev_\")\n",
    "        or c.startswith(\"inj_\")\n",
    "        or c.endswith(\"_diff_5\")\n",
    "        or c.endswith(\"_ratio_5\")\n",
    "        or c == \"days_since_last_injury\"):\n",
    "        final_cols.append(c)\n",
    "\n",
    "final_features_df = df[final_cols].copy()\n",
    "\n",
    "print(\"Final feature columns for modeling:\")\n",
    "print(final_features_df.columns.tolist())\n",
    "\n",
    "print(\"Sample of final features:\")\n",
    "print(final_features_df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T17:11:33.911337Z",
     "iopub.status.busy": "2025-04-08T17:11:33.910963Z",
     "iopub.status.idle": "2025-04-08T17:11:33.924879Z",
     "shell.execute_reply": "2025-04-08T17:11:33.923744Z",
     "shell.execute_reply.started": "2025-04-08T17:11:33.911306Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prev_substitutes_out              88\n",
       "prev_cards_yellow                 88\n",
       "prev_goals_total                  88\n",
       "prev_games_appearences            88\n",
       "prev_cards_red                    88\n",
       "prev_games_lineups                88\n",
       "prev_cards_yellowred              88\n",
       "prev_goals_conceded              150\n",
       "prev_penalty_scored              150\n",
       "prev_penalty_missed              150\n",
       "days_since_last_injury           165\n",
       "prev_passes_total                194\n",
       "prev_games_rating                194\n",
       "prev_duels_won                   197\n",
       "prev_duels_total                 197\n",
       "prev_fouls_drawn                 214\n",
       "prev_tackles_interceptions       227\n",
       "prev_tackles_total               229\n",
       "prev_shots_total                 232\n",
       "prev_fouls_committed             236\n",
       "prev_passes_key                  241\n",
       "prev_dribbles_attempts           254\n",
       "prev_dribbles_success            261\n",
       "prev_goals_assists               325\n",
       "prev_shots_on                    341\n",
       "prev_tackles_blocks              351\n",
       "team_pass_acc_ratio_5            653\n",
       "team_ball_poss_avg_5             653\n",
       "team_vs_opp_shots_ratio_5        675\n",
       "team_vs_opp_fouls_ratio_5        675\n",
       "opp_pass_acc_ratio_5             675\n",
       "opp_ball_poss_avg_5              675\n",
       "team_vs_opp_sog_ratio_5          677\n",
       "team_vs_opp_corners_ratio_5      682\n",
       "team_vs_opp_offsides_ratio_5     734\n",
       "prev_passes_accuracy             779\n",
       "team_vs_opp_pass_acc_diff_5      830\n",
       "team_vs_opp_poss_diff_5          830\n",
       "team_vs_opp_pass_acc_ratio_5     830\n",
       "team_vs_opp_poss_ratio_5         830\n",
       "player_minutes_avg_5             885\n",
       "player_rating_avg_5              885\n",
       "player_pass_acc_mean_5           885\n",
       "player_duels_win_ratio_5         894\n",
       "prev_penalty_saved               962\n",
       "prev_goals_saves                 965\n",
       "prev_dribbles_past              1000\n",
       "prev_games_number               1000\n",
       "prev_penalty_won                1000\n",
       "prev_penalty_commited           1000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum().sort_values().tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T17:12:04.028166Z",
     "iopub.status.busy": "2025-04-08T17:12:04.027759Z",
     "iopub.status.idle": "2025-04-08T17:12:04.166189Z",
     "shell.execute_reply": "2025-04-08T17:12:04.164381Z",
     "shell.execute_reply.started": "2025-04-08T17:12:04.028136Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"final_df2.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7086591,
     "sourceId": 11328764,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
